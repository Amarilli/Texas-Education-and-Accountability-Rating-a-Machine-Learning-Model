{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = pd.read_csv('Resources/tor20.21.csv')\n",
    "staar = pd.read_csv('Resources/staar20.21.cleaned.csv')\n",
    "teacher = pd.read_csv('Resources/teachers_scores20_21.csv')\n",
    "all_info = pd.read_csv('Resources/DISTRICTS_INFO_2020.21.csv')\n",
    "staar19 = pd.read_csv('Resources/staar19_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "completedf = pd.merge(staar19, all_info, on='DISTRICT NAME', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "completedf['Change in STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD'] = completedf['STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD'] - completedf[' STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD']\n",
    "completedf['Change in STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE'] = completedf['STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_y'] - completedf['STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_x']\n",
    "completedf['Change in STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE'] = completedf['STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y'] - completedf['STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISTRICT NAME',\n",
       " 'STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " ' STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % ELA/READING AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % ELA/READING AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % ELA/READING AT MASTERS GRADE LEVEL STANDARD_x',\n",
       " 'STAAR: % WRITING AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % WRITING AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % WRITING AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % MATHEMATICS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % MATHEMATICS AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % MATHEMATICS AT MASTERS GRADE LEVEL STANDARD_x',\n",
       " 'STAAR: % SCIENCE AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % SCIENCE AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % SCIENCE AT MASTERS GRADE LEVEL STANDARD_x',\n",
       " 'STAAR: % SOCIAL STUDIES AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % SOCIAL STUDIES AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " ' STAAR: % SOCIAL STUDIES AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'DISTRICT NUMBER',\n",
       " 'COUNTY NUMBER AND NAME',\n",
       " 'EDUCATION SERVICE CENTER REGION',\n",
       " 'DISTRICT ACCOUNTABILITY RATINGS',\n",
       " 'TOTAL NUMBER OF SCHOOLS',\n",
       " 'TOTAL STUDENTS',\n",
       " 'STUDENTS: % AFRICAN AMERICAN',\n",
       " 'STUDENTS: % HISPANIC',\n",
       " 'STUDENTS: % WHITE',\n",
       " 'STUDENTS: % AMERICAN INDIAN',\n",
       " 'STUDENTS: % ASIAN',\n",
       " 'STUDENTS: % PACIFIC ISLANDER',\n",
       " 'STUDENTS: % TWO OR MORE RACES',\n",
       " 'STUDENTS: % ECONOMICALLY DISADVANTAGED',\n",
       " 'STUDENTS: % ENGLISH LEARNERS (EL)',\n",
       " 'STUDENTS: % SPECIAL EDUCATION',\n",
       " 'STUDENTS: % BILINGUAL/ESL EDUCATION',\n",
       " 'STUDENTS: % CAREER & TECHNICAL EDUCATION',\n",
       " 'STUDENTS: % GIFTED & TALENTED EDUCATION',\n",
       " 'ATTENDANCE RATE (2020-21)',\n",
       " 'ANNUAL DROPOUT RATE GR. 9-12 (2020-21)',\n",
       " '4-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2021) DISTRICT EXCL',\n",
       " '5-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2020) DISTRICT EXCL',\n",
       " ' 6-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2019) DISTRICT EXCL',\n",
       " 'ANNUAL GRADUATE COUNT (2020-21)',\n",
       " 'ANNUAL RHSP/DAP/FHSP-E/FHSP-DLA GRADUATE COUNT (2020-21)',\n",
       " 'STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % ELA/READING AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % ELA/READING AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % ELA/READING AT MASTERS GRADE LEVEL STANDARD_y',\n",
       " 'STAAR: % MATHEMATICS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % MATHEMATICS AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % MATHEMATICS AT MASTERS GRADE LEVEL STANDARD_y',\n",
       " 'STAAR: % SCIENCE AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % SCIENCE AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % SCIENCE AT MASTERS GRADE LEVEL STANDARD_y',\n",
       " 'STAAR: % SOCIAL STUDIES AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " ' STAAR: % SOCIAL STUDIES AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % SOCIAL STUDIES AT MASTERS GRADE LEVEL STANDARD',\n",
       " ' STAAR: % AFRICAN AMERICAN AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % AFRICAN AMERICAN AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % AFRICAN AMERICAN AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % HISPANIC AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % HISPANIC AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % HISPANIC AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % WHITE AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % WHITE AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % WHITE AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % AMERICAN INDIAN AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % AMERICAN INDIAN AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % AMERICAN INDIAN AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % ASIAN AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % ASIAN AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % ASIAN AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % PACIFIC ISLANDER AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % PACIFIC ISLANDER AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % PACIFIC ISLANDER AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % TWO OR MORE RACES AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % TWO OR MORE RACES AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " ' STAAR: % TWO OR MORE RACES AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'STAAR: % ECONOMICALLY DISADVANTAGED AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % ECONOMICALLY DISADVANTAGED AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'STAAR: % ECONOMICALLY DISADVANTAGED AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'COLLEGE ADMISSIONS: % TESTED (2020-2021)',\n",
       " 'COLLEGE ADMISSIONS: % AT/ABOVE CRITERION (2020-2021)',\n",
       " 'SAT-AVERAGE SCORE (2021-2020)',\n",
       " 'ACT-AVERAGE SCORE (2021-2020)',\n",
       " 'TOTAL STAFF FTE',\n",
       " 'TOTAL TEACHER FTE',\n",
       " 'STAFF: % CENTRAL ADMINISTRATIVE',\n",
       " 'STAFF: % SCHOOL ADMINISTRATIVE',\n",
       " 'STAFF: % PROFESSIONAL SUPPORT',\n",
       " 'STAFF: % TEACHERS',\n",
       " 'STAFF: % EDUCATIONAL AIDES',\n",
       " 'STAFF: % AUXILIARY',\n",
       " 'AVERAGE SALARY: CENTRAL ADMINISTRATIVE',\n",
       " 'AVERAGE SALARY: SCHOOL ADMINISTRATIVE',\n",
       " 'AVERAGE SALARY: PROFESSIONAL SUPPORT',\n",
       " 'AVERAGE SALARY: TEACHER',\n",
       " 'STAFF: % MINORITY',\n",
       " 'NUMBER OF STUDENTS PER TOTAL STAFF',\n",
       " 'NUMBER OF STUDENTS PER TEACHER',\n",
       " 'TEACHER: % WITH 5 OR FEWER YEARS OF EXPERIENCE',\n",
       " 'TEACHER: AVERAGE YEARS OF EXPERIENCE',\n",
       " 'TEACHER: % WITH ADVANCED DEGREES',\n",
       " 'TEACHER: TURNOVER RATE',\n",
       " 'TEACHER: % AFRICAN AMERICAN',\n",
       " 'TEACHER: % HISPANIC',\n",
       " 'TEACHER: % WHITE',\n",
       " 'TEACHER: % AMERICAN INDIAN',\n",
       " 'TEACHER: % ASIAN',\n",
       " 'TEACHER: % PACIFIC ISLANDER',\n",
       " 'TEACHER: % TWO OR MORE RACES',\n",
       " 'TEACHER: % REGULAR EDUCATION',\n",
       " 'TEACHER: % SPECIAL EDUCATION',\n",
       " 'TEACHER: % COMPENSATORY EDUCATION',\n",
       " 'TEACHER: % BILINGUAL/ESL EDUCATION',\n",
       " 'TEACHER: % CAREER & TECHNICAL EDUCATION',\n",
       " 'TEACHER: % OTHER EDUCATION (INCLUDES G & T)',\n",
       " 'TAXABLE VALUE PER PUPIL (2019 TAX YEAR)',\n",
       " 'LOCALLY ADOPTED TAX RATE (2020 TAX YEAR)',\n",
       " 'TOTAL OPERATING AND OTHER REVENUE (2020-21)',\n",
       " 'Total OPERATING AND OTHER REVENUE PER PUPIL',\n",
       " 'Total OPERATING REVENUE (2020-21)',\n",
       " 'REVENUE: % STATE',\n",
       " 'REVENUE: % LOCAL AND OTHER',\n",
       " 'REVENUE: % FEDERAL',\n",
       " 'TOTAL OTHER REVENUE(2020-21)',\n",
       " 'FUND BALANCE (FOR ISDS)',\n",
       " 'NET ASSETS (CHARTER SCHOOLS)',\n",
       " 'TOTAL ACTUAL EXPENDITURES (2020-21)',\n",
       " 'TOTAL ACTUAL OPERATING EXPENDITURES (2020-21)',\n",
       " 'TOTAL ACTUAL OPERATING EXPENDITURES PER PUPIL',\n",
       " 'EXPENDITURE: % INSTRUCTIONAL',\n",
       " 'EXPENDITURE: % CENTRAL ADMINISTRATIVE',\n",
       " 'EXPENDITURE: % SCHOOL LEADERSHIP',\n",
       " 'EXPENDITURE: % PLANT SERVICES',\n",
       " 'EXPENDITURE: % OTHER OPERATING',\n",
       " 'TOTAL ACTUAL INSTRUCTIONAL EXPENDITURES',\n",
       " 'TOTAL ACTUAL INSTRUCTIONAL EXPENDITURES PER PUPIL',\n",
       " ' EXPENDITURE: % BASIC EDUCATION SERVICES',\n",
       " 'EXPENDITURE: % SPECIAL EDUCATION',\n",
       " 'EXPENDITURE: % STATE COMPENSATORY EDUCATION',\n",
       " 'EXPENDITURE: % BILINGUAL/ESL EDUCATION',\n",
       " 'EXPENDITURE: % CAREER & TECHNICAL EDUCATION',\n",
       " ' EXPENDITURE: % GIFTED & TALENTED EDUCATION',\n",
       " 'EXPENDITURE: % ATHLETICS/RELATED ACTIVITIES',\n",
       " 'EXPENDITURE: % HIGH SCHOOL ALLOTMENT',\n",
       " 'EXPENDITURE: % PREKINDERGARTEN',\n",
       " 'EXPENDITURE: % UN-ALLOCATED',\n",
       " 'DISTRICT SIZE',\n",
       " 'COMMUNITY TYPE',\n",
       " 'PROPERTY WEALTH',\n",
       " 'TAX RATE',\n",
       " 'Change in STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'Change in STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'Change in STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completedf.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "completedf = completedf.drop(columns=['DISTRICT NAME',\n",
    " 'STAAR: % ELA/READING AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % ELA/READING AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % ELA/READING AT MASTERS GRADE LEVEL STANDARD_x',\n",
    " 'STAAR: % WRITING AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % WRITING AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % WRITING AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % MATHEMATICS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % MATHEMATICS AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % MATHEMATICS AT MASTERS GRADE LEVEL STANDARD_x',\n",
    " 'STAAR: % SCIENCE AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % SCIENCE AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % SCIENCE AT MASTERS GRADE LEVEL STANDARD_x',\n",
    " 'STAAR: % SOCIAL STUDIES AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % SOCIAL STUDIES AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " ' STAAR: % SOCIAL STUDIES AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'DISTRICT NUMBER',\n",
    " 'COUNTY NUMBER AND NAME',\n",
    " 'EDUCATION SERVICE CENTER REGION',\n",
    " 'TOTAL NUMBER OF SCHOOLS',\n",
    " 'STUDENTS: % AFRICAN AMERICAN',\n",
    " 'STUDENTS: % HISPANIC',\n",
    " 'STUDENTS: % WHITE',\n",
    " 'STUDENTS: % AMERICAN INDIAN',\n",
    " 'STUDENTS: % ASIAN',\n",
    " 'STUDENTS: % PACIFIC ISLANDER',\n",
    " 'STUDENTS: % TWO OR MORE RACES',\n",
    " 'STUDENTS: % ECONOMICALLY DISADVANTAGED',\n",
    " 'STUDENTS: % ENGLISH LEARNERS (EL)',\n",
    " 'STUDENTS: % SPECIAL EDUCATION',\n",
    " 'STUDENTS: % BILINGUAL/ESL EDUCATION',\n",
    " 'STUDENTS: % CAREER & TECHNICAL EDUCATION',\n",
    " 'STUDENTS: % GIFTED & TALENTED EDUCATION',\n",
    " 'ANNUAL DROPOUT RATE GR. 9-12 (2020-21)',\n",
    " '5-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2020) DISTRICT EXCL',\n",
    " ' 6-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2019) DISTRICT EXCL',\n",
    " 'ANNUAL RHSP/DAP/FHSP-E/FHSP-DLA GRADUATE COUNT (2020-21)',\n",
    " 'STAAR: % ELA/READING AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % ELA/READING AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % ELA/READING AT MASTERS GRADE LEVEL STANDARD_y',\n",
    " 'STAAR: % MATHEMATICS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % MATHEMATICS AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % MATHEMATICS AT MASTERS GRADE LEVEL STANDARD_y',\n",
    " 'STAAR: % SCIENCE AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % SCIENCE AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % SCIENCE AT MASTERS GRADE LEVEL STANDARD_y',\n",
    " 'STAAR: % SOCIAL STUDIES AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " ' STAAR: % SOCIAL STUDIES AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % SOCIAL STUDIES AT MASTERS GRADE LEVEL STANDARD',\n",
    " ' STAAR: % AFRICAN AMERICAN AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % AFRICAN AMERICAN AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % AFRICAN AMERICAN AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % HISPANIC AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % HISPANIC AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % HISPANIC AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % WHITE AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % WHITE AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % WHITE AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % AMERICAN INDIAN AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % AMERICAN INDIAN AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % AMERICAN INDIAN AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % ASIAN AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % ASIAN AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % ASIAN AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % PACIFIC ISLANDER AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % PACIFIC ISLANDER AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % PACIFIC ISLANDER AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % TWO OR MORE RACES AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % TWO OR MORE RACES AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " ' STAAR: % TWO OR MORE RACES AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'STAAR: % ECONOMICALLY DISADVANTAGED AT APPROACHES GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % ECONOMICALLY DISADVANTAGED AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'STAAR: % ECONOMICALLY DISADVANTAGED AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'COLLEGE ADMISSIONS: % TESTED (2020-2021)',\n",
    " 'COLLEGE ADMISSIONS: % AT/ABOVE CRITERION (2020-2021)',\n",
    " 'SAT-AVERAGE SCORE (2021-2020)',\n",
    " 'ACT-AVERAGE SCORE (2021-2020)',\n",
    " 'TOTAL STAFF FTE',\n",
    " 'TOTAL TEACHER FTE',\n",
    " 'STAFF: % CENTRAL ADMINISTRATIVE',\n",
    " 'STAFF: % SCHOOL ADMINISTRATIVE',\n",
    " 'STAFF: % PROFESSIONAL SUPPORT',\n",
    " 'STAFF: % TEACHERS',\n",
    " 'STAFF: % EDUCATIONAL AIDES',\n",
    " 'STAFF: % AUXILIARY',\n",
    " 'AVERAGE SALARY: CENTRAL ADMINISTRATIVE',\n",
    " 'AVERAGE SALARY: SCHOOL ADMINISTRATIVE',\n",
    " 'AVERAGE SALARY: PROFESSIONAL SUPPORT',\n",
    " 'AVERAGE SALARY: TEACHER',\n",
    " 'STAFF: % MINORITY',\n",
    " 'NUMBER OF STUDENTS PER TOTAL STAFF',\n",
    " 'NUMBER OF STUDENTS PER TEACHER',\n",
    " 'TEACHER: % WITH 5 OR FEWER YEARS OF EXPERIENCE',\n",
    " 'TEACHER: % WITH ADVANCED DEGREES',\n",
    " 'TEACHER: TURNOVER RATE',\n",
    " 'TEACHER: % AFRICAN AMERICAN',\n",
    " 'TEACHER: % HISPANIC',\n",
    " 'TEACHER: % WHITE',\n",
    " 'TEACHER: % AMERICAN INDIAN',\n",
    " 'TEACHER: % ASIAN',\n",
    " 'TEACHER: % PACIFIC ISLANDER',\n",
    " 'TEACHER: % TWO OR MORE RACES',\n",
    " 'TEACHER: % REGULAR EDUCATION',\n",
    " 'TEACHER: % SPECIAL EDUCATION',\n",
    " 'TEACHER: % COMPENSATORY EDUCATION',\n",
    " 'TEACHER: % BILINGUAL/ESL EDUCATION',\n",
    " 'TEACHER: % CAREER & TECHNICAL EDUCATION',\n",
    " 'TEACHER: % OTHER EDUCATION (INCLUDES G & T)',\n",
    " 'TAXABLE VALUE PER PUPIL (2019 TAX YEAR)',\n",
    " 'LOCALLY ADOPTED TAX RATE (2020 TAX YEAR)',\n",
    " 'TOTAL OPERATING AND OTHER REVENUE (2020-21)',\n",
    " 'Total OPERATING AND OTHER REVENUE PER PUPIL',\n",
    " 'Total OPERATING REVENUE (2020-21)',\n",
    " 'REVENUE: % STATE',\n",
    " 'REVENUE: % LOCAL AND OTHER',\n",
    " 'REVENUE: % FEDERAL',\n",
    " 'TOTAL OTHER REVENUE(2020-21)',\n",
    " 'FUND BALANCE (FOR ISDS)',\n",
    " 'NET ASSETS (CHARTER SCHOOLS)',\n",
    " 'TOTAL ACTUAL EXPENDITURES (2020-21)',\n",
    " 'TOTAL ACTUAL OPERATING EXPENDITURES (2020-21)',\n",
    " 'TOTAL ACTUAL OPERATING EXPENDITURES PER PUPIL',\n",
    " 'EXPENDITURE: % INSTRUCTIONAL',\n",
    " 'EXPENDITURE: % CENTRAL ADMINISTRATIVE',\n",
    " 'EXPENDITURE: % SCHOOL LEADERSHIP',\n",
    " 'EXPENDITURE: % PLANT SERVICES',\n",
    " 'EXPENDITURE: % OTHER OPERATING',\n",
    " 'TOTAL ACTUAL INSTRUCTIONAL EXPENDITURES',\n",
    " 'TOTAL ACTUAL INSTRUCTIONAL EXPENDITURES PER PUPIL',\n",
    " ' EXPENDITURE: % BASIC EDUCATION SERVICES',\n",
    " 'EXPENDITURE: % SPECIAL EDUCATION',\n",
    " 'EXPENDITURE: % STATE COMPENSATORY EDUCATION',\n",
    " 'EXPENDITURE: % BILINGUAL/ESL EDUCATION',\n",
    " 'EXPENDITURE: % CAREER & TECHNICAL EDUCATION',\n",
    " ' EXPENDITURE: % GIFTED & TALENTED EDUCATION',\n",
    " 'EXPENDITURE: % ATHLETICS/RELATED ACTIVITIES',\n",
    " 'EXPENDITURE: % HIGH SCHOOL ALLOTMENT',\n",
    " 'EXPENDITURE: % PREKINDERGARTEN',\n",
    " 'EXPENDITURE: % UN-ALLOCATED',\n",
    " 'DISTRICT SIZE',\n",
    " 'PROPERTY WEALTH',\n",
    " 'TAX RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " 'STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
       " ' STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'DISTRICT ACCOUNTABILITY RATINGS',\n",
       " 'TOTAL STUDENTS',\n",
       " 'ATTENDANCE RATE (2020-21)',\n",
       " '4-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2021) DISTRICT EXCL',\n",
       " 'ANNUAL GRADUATE COUNT (2020-21)',\n",
       " 'STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
       " 'STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'TEACHER: AVERAGE YEARS OF EXPERIENCE',\n",
       " 'COMMUNITY TYPE',\n",
       " 'Change in STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
       " 'Change in STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
       " 'Change in STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completedf.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "completedf = pd.get_dummies(completedf, columns=['STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " 'STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_x',\n",
    " ' STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'TOTAL STUDENTS',\n",
    " 'ATTENDANCE RATE (2020-21)',\n",
    " '4-YR LONGITUDINAL GRADUATION RATE (CLASS OF 2021) DISTRICT EXCL',\n",
    " 'ANNUAL GRADUATE COUNT (2020-21)',\n",
    " 'STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE_y',\n",
    " 'STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'TEACHER: AVERAGE YEARS OF EXPERIENCE',\n",
    " 'COMMUNITY TYPE',\n",
    " 'Change in STAAR: % ALL SUBJECTS AT MASTERS GRADE LEVEL STANDARD',\n",
    " 'Change in STAAR: % ALL SUBJECTS AT MEETS GRADE LEVEL STANDARD OR ABOVE',\n",
    " 'Change in STAAR: % ALL SUBJECTS AT APPROACHES GRADE LEVEL STANDARD OR ABOVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "completedf = completedf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 2357)\n"
     ]
    }
   ],
   "source": [
    "# Remove 'DISTRICT ACCOUNTABILITY RATINGS' target from features data\n",
    "X = completedf.drop(columns=['DISTRICT ACCOUNTABILITY RATINGS']) \n",
    "y = completedf['DISTRICT ACCOUNTABILITY RATINGS']  \n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variables\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riahk\\anaconda3\\envs\\geoviews\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">188,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │       \u001b[38;5;34m188,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m8,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,311</span> (790.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,311\u001b[0m (790.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,311</span> (790.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,311\u001b[0m (790.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=2357))\n",
    "# Add more hidden layers\n",
    "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4018 - loss: 1.2347 - val_accuracy: 0.5056 - val_loss: 1.2412\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 1.0445 - val_accuracy: 0.5056 - val_loss: 1.1445\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 0.8825 - val_accuracy: 0.5056 - val_loss: 1.0951\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.6301 - val_accuracy: 0.6966 - val_loss: 1.0338\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.6375 - val_accuracy: 0.6742 - val_loss: 1.0254\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.6962 - val_accuracy: 0.6798 - val_loss: 1.0298\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.7637 - val_accuracy: 0.6798 - val_loss: 1.0309\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.6932 - val_accuracy: 0.6798 - val_loss: 1.0317\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 0.7043 - val_accuracy: 0.6798 - val_loss: 1.0325\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.6631 - val_accuracy: 0.6798 - val_loss: 1.0330\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.5974 - val_accuracy: 0.6798 - val_loss: 1.0336\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.4956 - val_accuracy: 0.6798 - val_loss: 1.0340\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.7504 - val_accuracy: 0.6798 - val_loss: 1.0344\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.8949 - val_accuracy: 0.6798 - val_loss: 1.0348\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.8150 - val_accuracy: 0.6798 - val_loss: 1.0352\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.5298 - val_accuracy: 0.6798 - val_loss: 1.0355\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.7306 - val_accuracy: 0.6798 - val_loss: 1.0358\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.5576 - val_accuracy: 0.6798 - val_loss: 1.0361\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.7531 - val_accuracy: 0.6798 - val_loss: 1.0364\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.8379 - val_accuracy: 0.6798 - val_loss: 1.0367\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.6786 - val_accuracy: 0.6798 - val_loss: 1.0369\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.6383 - val_accuracy: 0.6798 - val_loss: 1.0372\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.7879 - val_accuracy: 0.6798 - val_loss: 1.0374\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.6763 - val_accuracy: 0.6798 - val_loss: 1.0377\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.5549 - val_accuracy: 0.6798 - val_loss: 1.0379\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.5938 - val_accuracy: 0.6798 - val_loss: 1.0381\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.7184 - val_accuracy: 0.6798 - val_loss: 1.0383\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.6936 - val_accuracy: 0.6798 - val_loss: 1.0385\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.8945 - val_accuracy: 0.6798 - val_loss: 1.0388\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.6402 - val_accuracy: 0.6798 - val_loss: 1.0390\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.5781 - val_accuracy: 0.6798 - val_loss: 1.0392\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.5566 - val_accuracy: 0.6798 - val_loss: 1.0393\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.8716 - val_accuracy: 0.6798 - val_loss: 1.0395\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.6713 - val_accuracy: 0.6798 - val_loss: 1.0397\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.8676 - val_accuracy: 0.6798 - val_loss: 1.0399\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.6528 - val_accuracy: 0.6798 - val_loss: 1.0400\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.7235 - val_accuracy: 0.6798 - val_loss: 1.0402\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.7182 - val_accuracy: 0.6798 - val_loss: 1.0403\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.6623 - val_accuracy: 0.6798 - val_loss: 1.0405\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8543 - loss: 0.9143 - val_accuracy: 0.6798 - val_loss: 1.0406\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.6297 - val_accuracy: 0.6798 - val_loss: 1.0408\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.6653 - val_accuracy: 0.6798 - val_loss: 1.0409\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.6240 - val_accuracy: 0.6798 - val_loss: 1.0411\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.6780 - val_accuracy: 0.6798 - val_loss: 1.0412\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.7487 - val_accuracy: 0.6798 - val_loss: 1.0414\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.6567 - val_accuracy: 0.6798 - val_loss: 1.0415\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.5749 - val_accuracy: 0.6798 - val_loss: 1.0416\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.6896 - val_accuracy: 0.6798 - val_loss: 1.0418\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.8073 - val_accuracy: 0.6798 - val_loss: 1.0419\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.5942 - val_accuracy: 0.6798 - val_loss: 1.0420\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.5624 - val_accuracy: 0.6798 - val_loss: 1.0422\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.6960 - val_accuracy: 0.6798 - val_loss: 1.0423\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.6614 - val_accuracy: 0.6798 - val_loss: 1.0424\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.6105 - val_accuracy: 0.6798 - val_loss: 1.0425\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.5446 - val_accuracy: 0.6798 - val_loss: 1.0426\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.6321 - val_accuracy: 0.6798 - val_loss: 1.0427\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.5776 - val_accuracy: 0.6798 - val_loss: 1.0428\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.7332 - val_accuracy: 0.6798 - val_loss: 1.0429\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.6357 - val_accuracy: 0.6798 - val_loss: 1.0430\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.7058 - val_accuracy: 0.6798 - val_loss: 1.0431\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.5817 - val_accuracy: 0.6798 - val_loss: 1.0432\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.6106 - val_accuracy: 0.6798 - val_loss: 1.0433\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.7325 - val_accuracy: 0.6798 - val_loss: 1.0434\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.7157 - val_accuracy: 0.6798 - val_loss: 1.0435\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.5508 - val_accuracy: 0.6798 - val_loss: 1.0436\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.7464 - val_accuracy: 0.6798 - val_loss: 1.0437\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.7159 - val_accuracy: 0.6798 - val_loss: 1.0437\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.6976 - val_accuracy: 0.6798 - val_loss: 1.0438\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.7354 - val_accuracy: 0.6798 - val_loss: 1.0439\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.7051 - val_accuracy: 0.6798 - val_loss: 1.0440\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.7340 - val_accuracy: 0.6798 - val_loss: 1.0441\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.5320 - val_accuracy: 0.6798 - val_loss: 1.0441\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.8088 - val_accuracy: 0.6798 - val_loss: 1.0442\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.6413 - val_accuracy: 0.6798 - val_loss: 1.0443\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.6009 - val_accuracy: 0.6798 - val_loss: 1.0443\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.6872 - val_accuracy: 0.6798 - val_loss: 1.0444\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.6257 - val_accuracy: 0.6798 - val_loss: 1.0445\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.7309 - val_accuracy: 0.6798 - val_loss: 1.0446\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.5854 - val_accuracy: 0.6798 - val_loss: 1.0446\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.7058 - val_accuracy: 0.6798 - val_loss: 1.0447\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.7097 - val_accuracy: 0.6798 - val_loss: 1.0448\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.7710 - val_accuracy: 0.6798 - val_loss: 1.0448\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.7401 - val_accuracy: 0.6798 - val_loss: 1.0449\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.7309 - val_accuracy: 0.6798 - val_loss: 1.0450\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.5911 - val_accuracy: 0.6798 - val_loss: 1.0450\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.6927 - val_accuracy: 0.6798 - val_loss: 1.0451\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.6639 - val_accuracy: 0.6798 - val_loss: 1.0451\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.6868 - val_accuracy: 0.6798 - val_loss: 1.0452\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.7128 - val_accuracy: 0.6798 - val_loss: 1.0453\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.7331 - val_accuracy: 0.6798 - val_loss: 1.0453\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.5836 - val_accuracy: 0.6798 - val_loss: 1.0454\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.8542 - val_accuracy: 0.6798 - val_loss: 1.0455\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.7985 - val_accuracy: 0.6798 - val_loss: 1.0455\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.6783 - val_accuracy: 0.6798 - val_loss: 1.0456\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.7184 - val_accuracy: 0.6798 - val_loss: 1.0457\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8756 - loss: 0.6763 - val_accuracy: 0.6798 - val_loss: 1.0457\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.6754 - val_accuracy: 0.6798 - val_loss: 1.0458\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 1.0006 - val_accuracy: 0.6798 - val_loss: 1.0458\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.5871 - val_accuracy: 0.6798 - val_loss: 1.0459\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.5015 - val_accuracy: 0.6798 - val_loss: 1.0459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x268e3ca2a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train_encoded, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 2ms/step - accuracy: 0.6892 - loss: 0.7721\n",
      "Loss: 0.7720528841018677, Accuracy: 0.6891891956329346\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test_encoded,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">301,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m301,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">313,089</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m313,089\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">312,641</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m312,641\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4077 - loss: 3.6769 - val_accuracy: 0.3652 - val_loss: 2.9385\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4703 - loss: 1.9744 - val_accuracy: 0.3820 - val_loss: 2.0803\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4517 - loss: 1.4997 - val_accuracy: 0.4213 - val_loss: 1.6974\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5374 - loss: 1.2180 - val_accuracy: 0.4775 - val_loss: 1.4829\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5761 - loss: 0.8438 - val_accuracy: 0.5225 - val_loss: 1.3557\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5731 - loss: 0.7727 - val_accuracy: 0.5506 - val_loss: 1.2700\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.6741 - val_accuracy: 0.5787 - val_loss: 1.2136\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6484 - loss: 0.5517 - val_accuracy: 0.5393 - val_loss: 1.2087\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.5832 - val_accuracy: 0.5506 - val_loss: 1.1667\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.5240 - val_accuracy: 0.5449 - val_loss: 1.1356\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6458 - loss: 0.5485 - val_accuracy: 0.5618 - val_loss: 1.1320\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 0.4587 - val_accuracy: 0.5337 - val_loss: 1.1229\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6435 - loss: 0.4440 - val_accuracy: 0.5281 - val_loss: 1.1055\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.4213 - val_accuracy: 0.5393 - val_loss: 1.1189\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6841 - loss: 0.3858 - val_accuracy: 0.5393 - val_loss: 1.0928\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6773 - loss: 0.4993 - val_accuracy: 0.5337 - val_loss: 1.1038\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6798 - loss: 0.4548 - val_accuracy: 0.5393 - val_loss: 1.0830\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.3646 - val_accuracy: 0.5281 - val_loss: 1.0893\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.3117 - val_accuracy: 0.5225 - val_loss: 1.0830\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.3512 - val_accuracy: 0.5449 - val_loss: 1.1003\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.3275 - val_accuracy: 0.5393 - val_loss: 1.0914\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.3529 - val_accuracy: 0.5393 - val_loss: 1.0846\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.2661 - val_accuracy: 0.5393 - val_loss: 1.0971\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6818 - loss: 0.3303 - val_accuracy: 0.5281 - val_loss: 1.0987\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.2856 - val_accuracy: 0.5506 - val_loss: 1.1189\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7544 - loss: 0.2811 - val_accuracy: 0.5449 - val_loss: 1.0810\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.2423 - val_accuracy: 0.5506 - val_loss: 1.0835\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7477 - loss: 0.2403 - val_accuracy: 0.5393 - val_loss: 1.0621\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.2900 - val_accuracy: 0.5337 - val_loss: 1.0335\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7567 - loss: 0.2525 - val_accuracy: 0.5562 - val_loss: 1.0312\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7655 - loss: 0.2628 - val_accuracy: 0.5393 - val_loss: 1.0461\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.2810 - val_accuracy: 0.5449 - val_loss: 1.0453\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.2331 - val_accuracy: 0.5393 - val_loss: 1.0504\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 0.2030 - val_accuracy: 0.5506 - val_loss: 1.0140\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.3096 - val_accuracy: 0.5562 - val_loss: 1.0445\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7524 - loss: 0.1977 - val_accuracy: 0.5449 - val_loss: 1.0513\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7564 - loss: 0.2295 - val_accuracy: 0.5506 - val_loss: 1.0079\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7538 - loss: 0.1952 - val_accuracy: 0.5337 - val_loss: 1.0240\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.2134 - val_accuracy: 0.5449 - val_loss: 1.0214\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7774 - loss: 0.1713 - val_accuracy: 0.5337 - val_loss: 1.0323\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.2808 - val_accuracy: 0.5449 - val_loss: 1.0007\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7482 - loss: 0.2748 - val_accuracy: 0.5449 - val_loss: 0.9949\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.1915 - val_accuracy: 0.5449 - val_loss: 1.0161\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7528 - loss: 0.2126 - val_accuracy: 0.5449 - val_loss: 1.0421\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.1932 - val_accuracy: 0.5506 - val_loss: 1.0378\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.2160 - val_accuracy: 0.5393 - val_loss: 1.0399\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.2018 - val_accuracy: 0.5337 - val_loss: 1.0550\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.2039 - val_accuracy: 0.5449 - val_loss: 1.0411\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7784 - loss: 0.1643 - val_accuracy: 0.5393 - val_loss: 1.0594\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.1872 - val_accuracy: 0.5449 - val_loss: 1.0572\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7724 - loss: 0.1854 - val_accuracy: 0.5281 - val_loss: 1.0281\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.1470 - val_accuracy: 0.5449 - val_loss: 1.0281\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.1847 - val_accuracy: 0.5393 - val_loss: 1.0112\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.1887 - val_accuracy: 0.5449 - val_loss: 1.0417\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.1604 - val_accuracy: 0.5562 - val_loss: 0.9980\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.1908 - val_accuracy: 0.5449 - val_loss: 0.9886\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.1830 - val_accuracy: 0.5562 - val_loss: 0.9951\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.1654 - val_accuracy: 0.5506 - val_loss: 0.9813\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.1399 - val_accuracy: 0.5449 - val_loss: 0.9571\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7608 - loss: 0.1709 - val_accuracy: 0.5618 - val_loss: 0.9603\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.1467 - val_accuracy: 0.5899 - val_loss: 0.9467\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.1300 - val_accuracy: 0.5787 - val_loss: 0.9593\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.1761 - val_accuracy: 0.5843 - val_loss: 0.9416\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.1916 - val_accuracy: 0.5787 - val_loss: 0.9374\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.2205 - val_accuracy: 0.5955 - val_loss: 0.9387\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.1442 - val_accuracy: 0.5955 - val_loss: 0.9578\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.1482 - val_accuracy: 0.5787 - val_loss: 0.9615\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.1446 - val_accuracy: 0.5899 - val_loss: 0.9502\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.1589 - val_accuracy: 0.5843 - val_loss: 0.9619\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.1593 - val_accuracy: 0.5843 - val_loss: 0.9523\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.1365 - val_accuracy: 0.5730 - val_loss: 0.9886\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.1470 - val_accuracy: 0.5843 - val_loss: 0.9770\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7928 - loss: 0.1382 - val_accuracy: 0.5843 - val_loss: 0.9621\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.1344 - val_accuracy: 0.5843 - val_loss: 0.9680\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.1407 - val_accuracy: 0.5843 - val_loss: 0.9653\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.1724 - val_accuracy: 0.5899 - val_loss: 0.9431\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.1208 - val_accuracy: 0.5843 - val_loss: 0.9321\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.1274 - val_accuracy: 0.5843 - val_loss: 0.9546\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.1632 - val_accuracy: 0.5955 - val_loss: 0.9573\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.1368 - val_accuracy: 0.6011 - val_loss: 0.9474\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.1277 - val_accuracy: 0.5955 - val_loss: 0.9472\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.1338 - val_accuracy: 0.5955 - val_loss: 0.9279\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.1305 - val_accuracy: 0.5955 - val_loss: 0.9511\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.1418 - val_accuracy: 0.6011 - val_loss: 0.9313\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.1470 - val_accuracy: 0.5955 - val_loss: 0.9451\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.1333 - val_accuracy: 0.5899 - val_loss: 0.9510\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.1355 - val_accuracy: 0.6011 - val_loss: 0.9487\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.1205 - val_accuracy: 0.6067 - val_loss: 0.9399\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.1675 - val_accuracy: 0.5899 - val_loss: 0.9414\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8186 - loss: 0.1507 - val_accuracy: 0.5955 - val_loss: 0.9176\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.1086 - val_accuracy: 0.6011 - val_loss: 0.9066\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8133 - loss: 0.1504 - val_accuracy: 0.6067 - val_loss: 0.9081\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.1549 - val_accuracy: 0.6124 - val_loss: 0.9149\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.0993 - val_accuracy: 0.6011 - val_loss: 0.9311\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.1289 - val_accuracy: 0.5955 - val_loss: 0.9266\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8284 - loss: 0.1115 - val_accuracy: 0.5955 - val_loss: 0.9091\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.1140 - val_accuracy: 0.5955 - val_loss: 0.9265\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.1098 - val_accuracy: 0.5899 - val_loss: 0.9164\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.0996 - val_accuracy: 0.5955 - val_loss: 0.9141\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.1455 - val_accuracy: 0.5955 - val_loss: 0.9067\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Advanced Neural Network RMSE: 0.8485775134025458\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),  # Normalize the activations of the previous layer at each batch\n",
    "    Dropout(0.3),  # Randomly set a fraction of input units to 0 at each update during training\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['accuracy'])\n",
    "# Model summary to see the architecture\n",
    "model.summary()\n",
    "# Fit the model\n",
    "history = model.fit(X_train_scaled, y_train_encoded, validation_split=0.2, epochs=100, batch_size=32, verbose=1)\n",
    "# Evaluate the model\n",
    "y_pred_nn = model.predict(X_test_scaled).flatten()\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test_encoded, y_pred_nn))\n",
    "print(f'Advanced Neural Network RMSE: {rmse_nn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 2ms/step - accuracy: 0.6520 - loss: 0.6814\n",
      "Loss: 0.681442141532898, Accuracy: 0.6520270109176636\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test_encoded,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
